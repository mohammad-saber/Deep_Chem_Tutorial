{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f282bdd",
   "metadata": {},
   "source": [
    "# DeepChem\n",
    "\n",
    "- [Installation](https://github.com/deepchem/deepchem#installation)\n",
    "- [Tutorial](https://deepchem.readthedocs.io/en/latest/get_started/tutorials.html)\n",
    "- [Sample Notebooks](https://github.com/deepchem/deepchem/tree/master/examples/tutorials) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee150959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import deepchem as dc\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38904994",
   "metadata": {},
   "source": [
    "# Parameters , Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e36131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = './data/ESOL.csv' \n",
    "model_dir = './result'   # to save fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567e0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialze the metrics\n",
    "# https://deepchem.readthedocs.io/en/latest/api_reference/metrics.html\n",
    "metric_r2 = dc.metrics.Metric(dc.metrics.r2_score)\n",
    "metric_mse = dc.metrics.Metric(dc.metrics.mean_squared_error)\n",
    "metrics = [metric_r2, metric_mse]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee01ba",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5f1a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_filepath)   \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2157b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = data['smiles']   # should be 1D\n",
    "y = data['measured log solubility in mols per litre']   # can be 1D or 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6311f",
   "metadata": {},
   "source": [
    "# Make Dataset for DeepChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4902b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "# https://deepchem.readthedocs.io/en/latest/api_reference/featurizers.html\n",
    "featurizer = dc.feat.CircularFingerprint(radius=2, size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8854709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 1024)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"smiles\" can be Pandas Series or List. This method also accepts RDKit \"mol\" objects as input.\n",
    "# We don't apply feature selection here. This tutorial is an introduction of DeepChem. \n",
    "features = featurizer.featurize(smiles)   # array with shape : [No. of Samples, Size of Features]\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c0b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NumpyDataset X.shape: (1128, 1024), y.shape: (1128,), w.shape: (1128,), task_names: [0]>\n"
     ]
    }
   ],
   "source": [
    "# \"NumpyDataset\" class stores datasets in memory. This works fine for smaller datasets, but is less convenient for larger datasets. \n",
    "# For large datasets, use \"DiskDataset\" which writes dataset to a folder. \n",
    "# https://deepchem.readthedocs.io/en/latest/api_reference/data.html\n",
    "# https://github.com/deepchem/deepchem/blob/master/examples/tutorials/02_Working_With_Datasets.ipynb\n",
    "dataset = dc.data.NumpyDataset(X=features, y=np.array(y))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343892d",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0241b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"random splitting\" sometimes overestimates model’s performance, especially for small data or imbalance data. \n",
    "# The dc.splits provides more methods and algorithms to evaluate the model’s performance appropriately, like cross validation or splitting using molecular scaffolds.\n",
    "# https://deepchem.readthedocs.io/en/latest/api_reference/splitters.html\n",
    "\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset=dataset, \n",
    "            frac_train=0.7, frac_valid=0.15, frac_test=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c158e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NumpyDataset X.shape: (170, 1024), y.shape: (170,), w.shape: (170,), ids: [582 600 762 ... 578 106 4], task_names: [0]>\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91503aed",
   "metadata": {},
   "source": [
    "# Scikit-Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99cd8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "\n",
    "model = dc.models.SklearnModel(model=rf)\n",
    "\n",
    "# model training\n",
    "model.fit(train_dataset)\n",
    "\n",
    "valid_preds = model.predict(valid_dataset)\n",
    "test_preds = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d32508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'r2_score': 0.9413169878770975, 'mean_squared_error': 0.2739201150126245}\n",
      "Validation set score: {'r2_score': 0.6101626037769429, 'mean_squared_error': 1.4362241449299051}\n",
      "Test set score: {'r2_score': 0.6423432030476054, 'mean_squared_error': 1.3168607308163904}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, metrics))\n",
    "print(\"Validation set score:\", model.evaluate(valid_dataset, metrics))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ec61778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset (R2) :  0.6423432030476054\n",
      "Test dataset (RMSE) :  1.1475455245071502\n"
     ]
    }
   ],
   "source": [
    "# Since we have predicted values, we can use scikit-learn methods to calculate metrics as usual.\n",
    "y_test = test_dataset.y\n",
    "\n",
    "print(\"Test dataset (R2) : \", r2_score(y_test, test_preds))\n",
    "print(\"Test dataset (RMSE) : \", np.sqrt(mean_squared_error(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aecac1",
   "metadata": {},
   "source": [
    "# FNN Model (Fully-connected Neural Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e710253f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7227210235595704"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multitask regressor (fully connected network)\n",
    "# https://deepchem.readthedocs.io/en/latest/api_reference/models.html#multitaskregressor\n",
    "# layer_sizes : No. of nodes in every layer. In this example, a single hidden layer is used\n",
    "model = dc.models.MultitaskRegressor(n_tasks=1, n_features=1024, layer_sizes=[500])\n",
    "\n",
    "loss_avg = model.fit(train_dataset, nb_epoch=50)\n",
    "loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "663cbff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'r2_score': 0.9013138821838904, 'mean_squared_error': 0.4606463057097943}\n",
      "validation set score: {'r2_score': 0.508651307494114, 'mean_squared_error': 1.8102082114074893}\n",
      "test set score: {'r2_score': 0.502637112555131, 'mean_squared_error': 1.8312462143108037}\n"
     ]
    }
   ],
   "source": [
    "print('training set score:', model.evaluate(train_dataset, metrics))\n",
    "print('validation set score:', model.evaluate(valid_dataset, metrics))\n",
    "print('test set score:', model.evaluate(test_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a42ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset (R2) :  0.502637112555131\n",
      "Test dataset (RMSE) :  1.3532354615183582\n"
     ]
    }
   ],
   "source": [
    "valid_preds = model.predict(valid_dataset)\n",
    "test_preds = model.predict(test_dataset)\n",
    "\n",
    "print(\"Test dataset (R2) : \", r2_score(y_test, test_preds[:,:,0]))\n",
    "print(\"Test dataset (RMSE) : \", np.sqrt(mean_squared_error(y_test, test_preds[:,:,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0bc5d9",
   "metadata": {},
   "source": [
    "# Graph Convolution Featurizers\n",
    "\n",
    "\n",
    "DeepChem supports lots of different graph based models. Some of them require molecules to be featurized in slightly different ways. \n",
    "\n",
    "Because of this, there are two other featurizers called \"ConvMolFeaturizer\", \"WeaveFeaturizer\" and \"MolGraphConvFeaturizer\". \n",
    "\n",
    "They each convert molecules into a different type of Python object that is used by particular models. \n",
    "\n",
    "When using any graph based model, just check the documentation to see what featurizer you need to use with it.\n",
    "\n",
    "[Model Cheatsheet](https://deepchem.readthedocs.io/en/latest/api_reference/models.html#model-cheatsheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59443267",
   "metadata": {},
   "source": [
    "### ConvMolFeaturizer\n",
    "\n",
    "Duvenaud graph convolutions, Can be used with Keras models\n",
    "\n",
    "https://deepchem.readthedocs.io/en/latest/api_reference/featurizers.html#convmolfeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34d93eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepchem.feat.mol_graphs.ConvMol"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_smiles = [\"C\", \"CCC\", \"C1=CC=CN=C1\"]\n",
    "featurizer = dc.feat.ConvMolFeaturizer()\n",
    "features = featurizer.featurize(sample_smiles)   # numpy array, it returns a graph object for every molecule\n",
    "type(features[0])   # deepchem.feat.mol_graphs.ConvMol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7aabee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NumpyDataset X.shape: (3,), y.shape: (3, 1), w.shape: (3, 1), ids: [0 1 2], task_names: [0]>\n"
     ]
    }
   ],
   "source": [
    "# Make a dataset\n",
    "sample_dataset = dc.data.NumpyDataset(X=features)   # only X is enough\n",
    "print(sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25e2e7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<deepchem.feat.mol_graphs.ConvMol object at 0x7fb672579850> [0.] [0.] 0\n",
      "<deepchem.feat.mol_graphs.ConvMol object at 0x7fb6725d4750> [0.] [0.] 1\n",
      "<deepchem.feat.mol_graphs.ConvMol object at 0x7fb6725d4b10> [0.] [0.] 2\n"
     ]
    }
   ],
   "source": [
    "# Iterate over dataset\n",
    "# https://deepchem.readthedocs.io/en/latest/api_reference/data.html#deepchem.data.NumpyDataset.itersamples\n",
    "inputs = []\n",
    "for x, y, w, id in sample_dataset.itersamples():    \n",
    "    print(x, y, w, id)\n",
    "    inputs_ = [x.get_atom_features(), x.deg_slice, np.array(x.membership)]  \n",
    "    for i in range(1, len(x.get_deg_adjacency_lists())):\n",
    "        inputs_.append(x.get_deg_adjacency_lists()[i]) \n",
    "    inputs.append(inputs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74cb181",
   "metadata": {},
   "source": [
    "- Discussion about graph features:\n",
    "\n",
    "From the above code, we get graph features as numeric values. For every molecule, it is a List containing 13 numpy arrays.\n",
    "However, the size of arrays is different for every molecule (because No. of atoms is different).\n",
    "Therefore, it is not possible to concatenate features of all molecules altogether and make a DataFrame. Because DataFrame requires the same No. of columns for every row (which is a molecule in this case).\n",
    "\n",
    "- Note:\n",
    "\n",
    "When you use graph representation of a molecule, every atom has a feature vector. Since the No. of atoms is different in different molecules, the size of graph features is also different. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3af989",
   "metadata": {},
   "source": [
    "### MolGraphConvFeaturizer\n",
    "\n",
    "General graph convolution networks for molecules, Can be used with PyTorch models\n",
    "\n",
    " https://deepchem.readthedocs.io/en/latest/api_reference/featurizers.html#molgraphconvfeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e950538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepchem.feat.graph_data.GraphData"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_smiles = [\"CCC\", \"C1=CC=CN=C1\"]\n",
    "featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "features = featurizer.featurize(sample_smiles)   # it returns a graph object for every molecule\n",
    "type(features[0])   # deepchem.feat.graph_data.GraphData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd241016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of node features :  30\n",
      "No. of edge features :  11\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of node features : \", features[0].num_node_features)   # 30\n",
    "print(\"No. of edge features : \", features[0].num_edge_features)  # 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae3f03",
   "metadata": {},
   "source": [
    "# DeepChem datasets\n",
    "\n",
    "Look deeper into DeepChem datasets (inherited from MoleculeNet)\n",
    "\n",
    "We load one of the datasets (for regression task) and apply 'GraphConv' featurizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "058683ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks : ['measured log solubility in mols per litre'] \n",
      "\n",
      "<DiskDataset X.shape: (113,), y.shape: (113, 1), w.shape: (113, 1), ids: ['c1cc2ccc3cccc4ccc(c1)c2c34' 'Cc1cc(=O)[nH]c(=S)[nH]1'\n",
      " 'Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 ' ...\n",
      " 'c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43' 'Cc1occc1C(=O)Nc2ccccc2'\n",
      " 'OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O '], task_names: ['measured log solubility in mols per litre']>\n"
     ]
    }
   ],
   "source": [
    "# log solubility in mols per litre\n",
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "\n",
    "print(f'tasks : {tasks} \\n')\n",
    "print(test_dataset)   # DiskDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "690c5acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>-1.601145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c1cc2ccc3cccc4ccc(c1)c2c34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>0.208483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cc1cc(=O)[nH]c(=S)[nH]1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>-0.016027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X         y    w  \\\n",
       "0  <deepchem.feat.mol_graphs.ConvMol object at 0x... -1.601145  1.0   \n",
       "1  <deepchem.feat.mol_graphs.ConvMol object at 0x...  0.208483  1.0   \n",
       "2  <deepchem.feat.mol_graphs.ConvMol object at 0x... -0.016027  1.0   \n",
       "\n",
       "                                          ids  \n",
       "0                  c1cc2ccc3cccc4ccc(c1)c2c34  \n",
       "1                     Cc1cc(=O)[nH]c(=S)[nH]1  \n",
       "2  Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4   "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert into DataFrame\n",
    "test_dataset_df = test_dataset.to_dataframe()   # DataFrame\n",
    "test_dataset_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cf13b",
   "metadata": {},
   "source": [
    "#### What is transformers?\n",
    "\n",
    "https://deepchem.readthedocs.io/en/latest/api_reference/transformers.html#\n",
    "\n",
    "It includes methods to apply normalization and standard scaling on datasets. DeepChem datasets might have been transformed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74f07da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check transformer\n",
    "transformers[0]   # there is one transformer object (normalization)\n",
    "transformers[0].transform_X   # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8621a714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers[0].transform_y   # True --> When we calculate metrics, we need to pass transformers to inverse transform \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d625028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean : -3.7811586825371185e-16\n",
      "mean : 0.9999999999999994\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "y_train = train_dataset.y\n",
    "print(f'mean : {np.mean(y_train)}')   # 0\n",
    "print(f'mean : {np.std(y_train)}')    # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3261a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepchem.feat.mol_graphs.ConvMol"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_dataset.X   # array of graph objects\n",
    "type(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cfaa33",
   "metadata": {},
   "source": [
    "# Train Graph Convolution Model on DeepChem Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "425cd1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(363,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(363, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(988,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(988, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(909,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(909, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(176,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(176, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(361,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(361, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(1054,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(1054, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(915,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(915, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(156,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(156, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/opt/anaconda3/envs/GNN/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16439361572265626"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://deepchem.readthedocs.io/en/latest/api_reference/models.html#graphconvmodel\n",
    "# This Class uses Keras models\n",
    "model = dc.models.GraphConvModel(n_tasks=len(tasks),       # No. of tasks \n",
    "                                 graph_conv_layers=[64],   # Width of channels for the Graph Convolution Layers\n",
    "                                 dense_layer_size=128,     # Width of channels for Atom Level Dense Layer before GraphPool\n",
    "                                 dropout=0.2,              # Dropout probablity to use for each layer. The length of this list should equal len(graph_conv_layers)+1 (one value for each convolution layer, and one for the dense layer). Alternatively this may be a single value instead of a list, in which case the same value is used for every layer.\n",
    "                                 mode='regression',        # Either “classification” or “regression”\n",
    "                                 batch_size=100,           # Batch size for training and evaluating\n",
    "                                 model_dir=model_dir,      # Directory on disk where the model will be stored. If this is None, a temporary directory is created.\n",
    "                                 learning_rate=0.001\n",
    "                                )\n",
    "\n",
    "loss_avg = model.fit(train_dataset, nb_epoch=50)\n",
    "loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "581d8bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"private__graph_conv_keras_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "graph_conv (GraphConv)       multiple                  102144    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "graph_pool (GraphPool)       multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  8320      \n",
      "_________________________________________________________________\n",
      "graph_gather (GraphGather)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "trim_graph_output (TrimGraph multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  257       \n",
      "=================================================================\n",
      "Total params: 111,489\n",
      "Trainable params: 111,105\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()   # must be after \"model.fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3a89057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function KerasModel._compute_model at 0x7fb67175c560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Training set score: {'r2_score': 0.7832451199443394, 'mean_squared_error': 0.9258356402264704}\n",
      "Validation set score: {'r2_score': 0.5162568494802122, 'mean_squared_error': 1.8904103877036327}\n",
      "Test set score: {'r2_score': 0.49130788982575313, 'mean_squared_error': 2.2854767038117947}\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score:\", model.evaluate(train_dataset, metrics, transformers))\n",
    "print(\"Validation set score:\", model.evaluate(valid_dataset, metrics, transformers))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, metrics, transformers))\n",
    "\n",
    "# What is \"transformers\"?\n",
    "# These transformations must have been applied to dataset previously. The dataset will be untransformed for metric evaluation.\n",
    "# Transformers for evaluation. This argument is needed since train_dataset and valid_dataset may have been transformed for learning\n",
    "# and need the transform to be inverted before the metric can be evaluated on a model (inverse transform)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535812e8",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "639347b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49130788982575313"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input to the \"predict\" is \"dataset\"\n",
    "y_pred = model.predict(test_dataset)   # numpy array [n, 1]\n",
    "\n",
    "y_test = test_dataset.y\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8358bc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
